{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# _Scraping MyAnimeList for Top Anime Series using Python_\n", "\n", "\n", "#### _Use the \"Run\" button to execute the code._\n", "\n", "\n", "![anime_intro](https://i.imgur.com/O5qf0Ms.jpg)\n", "\n", "\n", "\n", "\n", "\n", "Anime originated in Japan and it has been phenomenal in capturing the audience in recent decades.The theatre release of animes in the past few months truely projects the extent of reach of animes .This is an art which  projects the emotions in an unbelievable way capturing the audience with its story telling .Anime music are super melodic and catchy .The escape it provides into a world of our imagination is truely remarkable. Because modern world culture has taken anime to its heart, this form of entertainment has significantly impacted personal relationships.Here I have scraped the website MyAnimeList and  provided the list of Top Animes around the world and ranked them according to the ratings and the link for the same is provided in the CSV file.\n", "\n", "   MyAnimeList is a large Anime Database and community. It provides an updated list of the world's most popular anime series [Top Anime Series](https://myanimelist.net/topanime.php) ,in different categories such as All Anime, Top Airing ,Top Upcoming ,Top TV Series ,Top Movies ,Top OVAs ,Top ONAs, Top Specials ,Most Popular, Most Favorited and the Rank,Name of the Series and the Ratings .\n", "\n", "\n", "\n", "![webpage_img](https://i.imgur.com/l8fysqD.png)\n", "\n", "\n", "Web Scraping is the process through which we extract data from a website, and save it in a form which is easy to read, to understand and to work on.\n", "\n", "In this project we retrieve the information in the webpage using python libraries such as [BeautifulSoup](https://beautiful-soup-4.readthedocs.io/en/latest/) and [Requests](https://requests.readthedocs.io/en/latest/)\n", "\n", "Here are the outline of the steps to be followed:                                       \n", "1)Download the webpage using Requests                              \n", "2)Extract information from the HTML source code of a webpage programmatically, using the BeautifulSoup library.               \n", "3)Create a BeautifulSoup object to parse the content within the Source code.                                   \n", "4)Compile the extracted information into python lists and dictionaries.                                      \n", "5)Create a dataframe of the scraped webpage using [pandas](https://pandas.pydata.org/docs/)                               \n", "6)Convert the pandas dataframe to a csv file.                                       \n", "7)Future work and reference\n", "\n", "The contents of the CSV at the end of the project  contains `Rank` , `Name` ,`url` and the `Ratings` and the values are like        \n", "`9,'Gintama',https://myanimelist.net/anime/9969/Gintama, 9.04`\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## _Downloading the webpage using requests_\n", "\n", "\n", "\n", "To understand web scraping, it\u2019s important to first understand that web pages are built with text-based mark-up languages \u2013 the most common being HTML.\n", "\n", "A mark-up language defines the structure of a website\u2019s content. Since there are universal components and tags of mark-up languages, this makes it much easier for web scrapers to pull all the information that it needs. Once the HTML is parsed, the scraper then extracts the necessary data and stores it.\n", "Note : Not all websites allow Web Scraping, especially when personal information of the users is involved, so we should always ensure that we do not explore too much, and don't get our hands on information which might belong to someone else. Websites generally have protections at place, and they would block our access to the website if they see us scraping a large amount of data from their website.\n", "\n", "\n", "When you access a URL like https://myanimelist.net/topanime.php using a web browser, it downloads the contents of the web page the URL points to and displays the output on the screen. Before we can extract information from a web page, we need to download the page using Python.\n", "\n", "We'll use a library called requests to download web pages from the internet. Let's begin by installing and importing the library.\n", "\n"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["!pip install requests --upgrade --quiet"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["import requests"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Downloading the webpage using requests.get function and getting the source code of the page into text format."]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["response=requests.get('https://myanimelist.net/topanime.php')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The contents of the web page can be accessed using the .text property of the response."]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["page_content=response.text"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"data": {"text/plain": ["'\\n<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\\n    \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\\n\\n<html lang=\"en\">\\n<head>\\n    \\n<link rel=\"preconnect\" href=\"//fonts.gstatic.com/\" crossorigin=\"anonymous\" />\\n<link rel=\"preconnect\" href=\"//fonts.googleapis.com/\" crossorigin=\"anonymous\" />\\n<link rel=\"preconnect\" href=\"//tags-cdn.deployads.com/\" crossorigin=\"anonymous\" />\\n<link rel=\"preconnect\" href=\"//www.googletagservices.com/\" crossorigin=\"anonymous\" />\\n<link rel=\"preconnect\" href=\"//www.googletagmanager.com/\" crossorigin=\"anonymous\"/>\\n<link rel=\"preconnect\" href=\"//apis.google.com/\" crossorigin=\"anonymous\"/>\\n<link rel=\"preconnect\" href=\"//pixel-sync.sitescout.com/\" crossorigin=\"anonymous\"/>\\n<link rel=\"preconnect\" href=\"//pixel.tapad.com/\" crossorigin=\"anonymous\"/>\\n<link rel=\"preconnect\" href=\"//c.deployads.com/\" crossorigin=\"anonymous\"/>\\n<link rel=\"preconnect\" href=\"//tpc.googlesyndication.com/\" crossorigin=\"anonymous\"/>\\n<link rel=\"preconnect\" href=\"//google'"]}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": ["page_content[0:1000]"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["<Response [200]>\n"]}], "source": ["print(response)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["requests.get returns a response object with the page contents and some information indicating whether the request was successful, using a status code. Learn more about HTTP status codes here: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status.\n", "\n", "If the request was successful, response.status_code is set to a value between 200 and 299."]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [{"data": {"text/plain": ["True"]}, "execution_count": 7, "metadata": {}, "output_type": "execute_result"}], "source": ["response.ok"]}, {"cell_type": "markdown", "metadata": {}, "source": ["What you see above is the source code of the web page. It written in a language called [HTML](https://developer.mozilla.org/en-US/docs/Web/HTML). It defines the content and structure of the web page.\n", "\n", "Let's save the contents to a file with the .html extension."]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": ["with open('topanime.html','w') as file:\n", "    file.write(page_content)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["You can now view the file using the \"File > Open\" menu option within Jupyter and clicking on topanime.html in the list of files displayed. Here's what you'll see when you open the file:\n", "\n", "![html_page](https://i.imgur.com/Np20H2n.png)\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The html page will give error while trying to get to the link given in the page.                                               Now we have successfully downloaded the web page using requests."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## _Parse the  HTML Source code using BeautifulSoup_\n", "To extract information from the HTML source code of a webpage programmatically, we can use the Beautiful Soup library. Let's install the library and import the [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/class) from the bs4 module.We create an object of the Beautifulsoup library and the object contains several properties and methods for extracting information from the HTML document.Beautiful Soup is a Python package for parsing HTML and XML documents. Beautiful Soup enables us to get data out of sequences of characters. It creates a parse tree for parsed pages that can be used to extract data from HTML. It's a handy tool when it comes to web scraping.\n", "\n", "![HTML_IMAGE](https://i.imgur.com/9mIMtZP.png)\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [], "source": ["#Install the beautifulsoup4 library\n", "!pip install beautifulsoup4 --upgrade --quiet"]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [], "source": ["#import the BeautifulSoup class fom the bs4 module\n", "from bs4 import BeautifulSoup"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Next, let's read the contents of the file  topanime.html and create a BeautifulSoup object to parse the content."]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [], "source": ["#reading the contents of the file \n", "with open ('topanime.html','r') as f:\n", "        topanime_htmlSource=f.read()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Displaying the first 1000 lines of the source code"]}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [{"data": {"text/plain": ["'\\n<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\\n    \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\\n\\n<html lang=\"en\">\\n<head>\\n    \\n<link rel=\"preconnect\" href=\"//fonts.gstatic.com/\" crossorigin=\"anonymous\" />\\n<link rel=\"preconnect\" href=\"//fonts.googleapis.com/\" crossorigin=\"anonymous\" />\\n<link rel=\"preconnect\" href=\"//tags-cdn.deployads.com/\" crossorigin=\"anonymous\" />\\n<link rel=\"preconnect\" href=\"//www.googletagservices.com/\" crossorigin=\"anonymous\" />\\n<link rel=\"preconnect\" href=\"//www.googletagmanager.com/\" crossorigin=\"anonymous\"/>\\n<link rel=\"preconnect\" href=\"//apis.google.com/\" crossorigin=\"anonymous\"/>\\n<link rel=\"preconnect\" href=\"//pixel-sync.sitescout.com/\" crossorigin=\"anonymous\"/>\\n<link rel=\"preconnect\" href=\"//pixel.tapad.com/\" crossorigin=\"anonymous\"/>\\n<link rel=\"preconnect\" href=\"//c.deployads.com/\" crossorigin=\"anonymous\"/>\\n<link rel=\"preconnect\" href=\"//tpc.googlesyndication.com/\" crossorigin=\"anonymous\"/>\\n<link rel=\"preconnect\" href=\"//google'"]}, "execution_count": 12, "metadata": {}, "output_type": "execute_result"}], "source": ["topanime_htmlSource[:1000]"]}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [], "source": ["# creating an object of the BeautifulSoup Library\n", "anime_doc_demo=BeautifulSoup(topanime_htmlSource,'html.parser')"]}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [{"data": {"text/plain": ["bs4.BeautifulSoup"]}, "execution_count": 14, "metadata": {}, "output_type": "execute_result"}], "source": ["type(anime_doc_demo)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Using the anime_doc_demo oject we can get information from the page."]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [], "source": ["def get_anime_doc (url):\n", "    response=requests.get(url)\n", "    if response.status_code != 200:\n", "        print(\"Status code :\",response.status_code)\n", "        raise exception (\"Failed to fetch the webpage\",url)\n", "    anime_doc=BeautifulSoup(response.text,'html.parser')\n", "    return anime_doc"]}, {"cell_type": "markdown", "metadata": {}, "source": ["`get_anime_doc` is a function that returns a BeautifulSoup object for the url provided as the argument for the function.anime_doc has properties that allow us to read through the tags and attributes of the source code to get the required information."]}, {"cell_type": "markdown", "metadata": {}, "source": ["   ## _Extract Rank,Anime_Name ,Anime_Links and  Ratings from page_"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### _Extracting rank tags and returning a list_ \n", "\n", "We have to inspect the elements of the webpage to get to the required tags and attributes."]}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [{"data": {"text/plain": ["[<td class=\"rank ac\" valign=\"top\">\n", " <span class=\"lightLink top-anime-rank-text rank1\">1</span>\n", " </td>,\n", " <td class=\"rank ac\" valign=\"top\">\n", " <span class=\"lightLink top-anime-rank-text rank1\">2</span>\n", " </td>,\n", " <td class=\"rank ac\" valign=\"top\">\n", " <span class=\"lightLink top-anime-rank-text rank1\">3</span>\n", " </td>,\n", " <td class=\"rank ac\" valign=\"top\">\n", " <span class=\"lightLink top-anime-rank-text rank1\">4</span>\n", " </td>,\n", " <td class=\"rank ac\" valign=\"top\">\n", " <span class=\"lightLink top-anime-rank-text rank1\">5</span>\n", " </td>]"]}, "execution_count": 16, "metadata": {}, "output_type": "execute_result"}], "source": ["#Extracting the td tags from the anime_doc and conerting it into a list rank_list\n", "rank_tags_demo=anime_doc_demo.find_all('td',class_='rank ac')\n", "rank_tags_demo[:5]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Lets define a function `get_ranks` that returns a list of ranks."]}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [], "source": ["def get_ranks(doc):\n", "    rank_tags=doc.find_all('td',class_='rank ac')\n", "    return [tag.text.strip() for tag in rank_tags]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### _Extracting anime name tags and returning a list_"]}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [], "source": ["#Extracting the h3 from the anime_doc_demo\n", "anime_name_tags_demo=anime_doc_demo.find_all('h3',class_='hoverinfo_trigger fl-l fs14 fw-b anime_ranking_h3')"]}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [{"data": {"text/plain": ["'Bleach: Sennen Kessen-hen'"]}, "execution_count": 19, "metadata": {}, "output_type": "execute_result"}], "source": ["#getting the value of anime_name_tags using index\n", "anime_name_tags_demo[2].text"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Lets define a function `get_anime_names` that returns a list of anime_names."]}, {"cell_type": "code", "execution_count": 20, "metadata": {}, "outputs": [], "source": ["def get_anime_names(doc):\n", "    anime_name_tags=doc.find_all('h3',class_=\"hoverinfo_trigger fl-l fs14 fw-b anime_ranking_h3\")\n", "    return [tag.text for tag in anime_name_tags]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### _Extracting anime link tags and returning a list_"]}, {"cell_type": "code", "execution_count": 21, "metadata": {}, "outputs": [], "source": ["#Extracting the a tags from the anime_doc \n", "anime_link_tags_demo=anime_doc_demo.find_all('h3',class_=\"hoverinfo_trigger fl-l fs14 fw-b anime_ranking_h3\")"]}, {"cell_type": "code", "execution_count": 22, "metadata": {}, "outputs": [{"data": {"text/plain": ["'https://myanimelist.net/anime/41467/Bleach__Sennen_Kessen-hen'"]}, "execution_count": 22, "metadata": {}, "output_type": "execute_result"}], "source": ["#getting the value of anime_link_tags using index\n", "anime_link_tags_demo[2].a['href']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Lets define a function `get_anime_links` that returns a list of anime_links."]}, {"cell_type": "code", "execution_count": 23, "metadata": {}, "outputs": [], "source": ["#function to get the values from the anime_link_tags\n", "def get_anime_links (doc):\n", "    anime_link_tags=doc.find_all('h3',class_=\"hoverinfo_trigger fl-l fs14 fw-b anime_ranking_h3\")\n", "    return [tag.a['href'] for tag in anime_link_tags]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### _Extracting rating  tags and returning a list_"]}, {"cell_type": "code", "execution_count": 24, "metadata": {}, "outputs": [{"data": {"text/plain": ["[<td class=\"score ac fs14\"><div class=\"js-top-ranking-score-col di-ib al\"><i class=\"icon-score-star fa-solid fa-star mr4 on\"></i><span class=\"text on score-label score-9\">9.15</span></div>\n", " </td>,\n", " <td class=\"score ac fs14\"><div class=\"js-top-ranking-score-col di-ib al\"><i class=\"icon-score-star fa-solid fa-star mr4 on\"></i><span class=\"text on score-label score-9\">9.11</span></div>\n", " </td>,\n", " <td class=\"score ac fs14\"><div class=\"js-top-ranking-score-col di-ib al\"><i class=\"icon-score-star fa-solid fa-star mr4 on\"></i><span class=\"text on score-label score-9\">9.09</span></div>\n", " </td>,\n", " <td class=\"score ac fs14\"><div class=\"js-top-ranking-score-col di-ib al\"><i class=\"icon-score-star fa-solid fa-star mr4 on\"></i><span class=\"text on score-label score-9\">9.08</span></div>\n", " </td>,\n", " <td class=\"score ac fs14\"><div class=\"js-top-ranking-score-col di-ib al\"><i class=\"icon-score-star fa-solid fa-star mr4 on\"></i><span class=\"text on score-label score-9\">9.07</span></div>\n", " </td>]"]}, "execution_count": 24, "metadata": {}, "output_type": "execute_result"}], "source": ["#Extracting the span tags from the anime_doc and converting it into a list ratings_list\n", "rating_tags_demo=anime_doc_demo.find_all('td',class_=\"score ac fs14\")\n", "rating_tags_demo[:5]"]}, {"cell_type": "code", "execution_count": 25, "metadata": {}, "outputs": [{"data": {"text/plain": ["'9.15'"]}, "execution_count": 25, "metadata": {}, "output_type": "execute_result"}], "source": ["#getting the value of rating_tags using index\n", "rating_tags_demo[0].span.text"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Lets define a function `get_ratings` that returns a list ."]}, {"cell_type": "code", "execution_count": 26, "metadata": {}, "outputs": [], "source": ["def get_ratings(doc) :\n", "    ratings_tag=doc.find_all('td',class_=\"score ac fs14\")\n", "    return [tag.span.text for tag in ratings_tag]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Defining a function `get_top_anime` that gets information from different pages using multiiple functions and returns a dictionary `anime_dict` containing rank as the key and corresponding to each key a dictionary containing `Rank `,`Anime_name`,`Anime_link` and `Ratings` as values."]}, {"cell_type": "code", "execution_count": 27, "metadata": {}, "outputs": [], "source": ["def get_top_anime (page_number):\n", "    base_url=\"https://myanimelist.net/topanime.php\"\n", "    n=(page_number-1)*50\n", "    url=base_url+\"?limit={}\".format(n)\n", "\n", "     \n", "    anime_doc=get_top_anime_doc(url)\n", "    ranks_list=get_rank_tags(anime_doc)\n", "    anime_names_list=get_anime_name_tags(anime_doc)\n", "    anime_links_list=get_anime_link_tags(anime_doc)\n", "    ratings_list=get_rating_tags(anime_doc)\n", "    anime_dict={}\n", "    for rank,name,link,rating in zip(ranks_list,anime_names_list,anime_links_list,ratings_list):\n", "                anime_dict[rank]={\n", "                    \"Rank\":rank,\n", "                    \"Anime_name\": name,\n", "                    \"Anime_link\":link,\n", "                    \"Ratings\":rating\n", "                }\n", "            \n", "    return anime_dict\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## _Functions_"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Defining a function `get_top_anime` to parse information from multiple pages,taking the argument number_of_pages as input from the user .We can now put together everything we've done so far to solve the problem to get an output with rows greater than 100 and columns greater than 3.Here a [zip](https://www.w3schools.com/python/ref_func_zip.asp) function is used to combine all the data belonging to a particular rank and create a dictionary of dictionaries for each rank."]}, {"cell_type": "code", "execution_count": 28, "metadata": {}, "outputs": [], "source": ["def get_top_anime_doc(url):\n", "    \n", "    response=requests.get(url)\n", "    if response.status_code != 200 :\n", "        print(\"Status code:\",response.status_code)\n", "        raise exception (\"Failed to fetch the webpage\",header_base_url)\n", "    anime_doc= BeautifulSoup(response.text,'html.parser')\n", "    return anime_doc\n", "\n", "def get_ratings(doc) :\n", "    ratings_tag=doc.find_all('td',class_=\"score ac fs14\")\n", "    return [tag.span.text for tag in ratings_tag]\n", "\n", "\n", "def get_anime_names(doc):\n", "    anime_name_tags=doc.find_all('h3',class_=\"hoverinfo_trigger fl-l fs14 fw-b anime_ranking_h3\")\n", "    return [tag.text for tag in anime_name_tags]\n", "\n", "\n", "def get_anime_links(doc):\n", "    anime_link_tags=doc.find_all('h3',class_=\"hoverinfo_trigger fl-l fs14 fw-b anime_ranking_h3\")\n", "    return [tag.a['href'] for tag in anime_link_tags]\n", "\n", "\n", "def get_ranks(doc):\n", "    rank_tags=doc.find_all('td',class_='rank ac')\n", "    return [tag.text.strip() for tag in rank_tags]\n", "\n", "\n", "def get_top_anime (page_number):\n", "    base_url=\"https://myanimelist.net/topanime.php\"\n", "    n=(page_number-1)*50\n", "    url=base_url+\"?limit={}\".format(n)\n", "    \n", "    anime_doc=get_top_anime_doc(url)\n", "    ranks_list=get_ranks(anime_doc)\n", "    anime_names_list=get_anime_names(anime_doc)\n", "    anime_links_list=get_anime_links(anime_doc)\n", "    ratings_list=get_ratings(anime_doc)\n", "    anime_dict={}\n", "    for rank,name,link,rating in zip(ranks_list,anime_names_list,anime_links_list,ratings_list):\n", "                anime_dict[rank]={\n", "                    \"Rank\":rank,\n", "                    \"Anime_name\": name,\n", "                    \"Anime_link\":link,\n", "                    \"Ratings\":rating\n", "                }\n", "            \n", "    return anime_dict"]}, {"cell_type": "markdown", "metadata": {}, "source": ["A dictionary containing 200 rows of data and 4 columns can be obtained using the above reusable functions and the number of pages can be increased or decreased  using the range in the for loop.Following is the data from page_number(2)"]}, {"cell_type": "code", "execution_count": 29, "metadata": {}, "outputs": [{"data": {"text/plain": ["{'51': {'Rank': '51',\n", "  'Anime_name': 'Odd Taxi',\n", "  'Anime_link': 'https://myanimelist.net/anime/46102/Odd_Taxi',\n", "  'Ratings': '8.70'},\n", " '52': {'Rank': '52',\n", "  'Anime_name': 'Vinland Saga Season 2',\n", "  'Anime_link': 'https://myanimelist.net/anime/49387/Vinland_Saga_Season_2',\n", "  'Ratings': '8.70'},\n", " '53': {'Rank': '53',\n", "  'Anime_name': 'Code Geass: Hangyaku no Lelouch',\n", "  'Anime_link': 'https://myanimelist.net/anime/1575/Code_Geass__Hangyaku_no_Lelouch',\n", "  'Ratings': '8.70'},\n", " '54': {'Rank': '54',\n", "  'Anime_name': \"Fate/stay night Movie: Heaven's Feel - III. Spring Song\",\n", "  'Anime_link': 'https://myanimelist.net/anime/33050/Fate_stay_night_Movie__Heavens_Feel_-_III_Spring_Song',\n", "  'Ratings': '8.69'},\n", " '55': {'Rank': '55',\n", "  'Anime_name': 'Great Teacher Onizuka',\n", "  'Anime_link': 'https://myanimelist.net/anime/245/Great_Teacher_Onizuka',\n", "  'Ratings': '8.69'},\n", " '56': {'Rank': '56',\n", "  'Anime_name': 'One Piece',\n", "  'Anime_link': 'https://myanimelist.net/anime/21/One_Piece',\n", "  'Ratings': '8.69'},\n", " '57': {'Rank': '57',\n", "  'Anime_name': 'Made in Abyss: Retsujitsu no Ougonkyou',\n", "  'Anime_link': 'https://myanimelist.net/anime/41084/Made_in_Abyss__Retsujitsu_no_Ougonkyou',\n", "  'Ratings': '8.68'},\n", " '58': {'Rank': '58',\n", "  'Anime_name': 'Mononoke Hime',\n", "  'Anime_link': 'https://myanimelist.net/anime/164/Mononoke_Hime',\n", "  'Ratings': '8.67'},\n", " '59': {'Rank': '59',\n", "  'Anime_name': 'JoJo no Kimyou na Bouken Part 6: Stone Ocean Part 3',\n", "  'Anime_link': 'https://myanimelist.net/anime/53273/JoJo_no_Kimyou_na_Bouken_Part_6__Stone_Ocean_Part_3',\n", "  'Ratings': '8.67'},\n", " '60': {'Rank': '60',\n", "  'Anime_name': 'Violet Evergarden',\n", "  'Anime_link': 'https://myanimelist.net/anime/33352/Violet_Evergarden',\n", "  'Ratings': '8.67'},\n", " '61': {'Rank': '61',\n", "  'Anime_name': 'Made in Abyss',\n", "  'Anime_link': 'https://myanimelist.net/anime/34599/Made_in_Abyss',\n", "  'Ratings': '8.66'},\n", " '62': {'Rank': '62',\n", "  'Anime_name': 'Mushishi',\n", "  'Anime_link': 'https://myanimelist.net/anime/457/Mushishi',\n", "  'Ratings': '8.66'},\n", " '63': {'Rank': '63',\n", "  'Anime_name': 'Hajime no Ippo: New Challenger',\n", "  'Anime_link': 'https://myanimelist.net/anime/5258/Hajime_no_Ippo__New_Challenger',\n", "  'Ratings': '8.66'},\n", " '64': {'Rank': '64',\n", "  'Anime_name': 'Howl no Ugoku Shiro',\n", "  'Anime_link': 'https://myanimelist.net/anime/431/Howl_no_Ugoku_Shiro',\n", "  'Ratings': '8.66'},\n", " '65': {'Rank': '65',\n", "  'Anime_name': 'Jujutsu Kaisen',\n", "  'Anime_link': 'https://myanimelist.net/anime/40748/Jujutsu_Kaisen',\n", "  'Ratings': '8.65'},\n", " '66': {'Rank': '66',\n", "  'Anime_name': 'Natsume Yuujinchou Shi',\n", "  'Anime_link': 'https://myanimelist.net/anime/11665/Natsume_Yuujinchou_Shi',\n", "  'Ratings': '8.65'},\n", " '67': {'Rank': '67',\n", "  'Anime_name': 'Shigatsu wa Kimi no Uso',\n", "  'Anime_link': 'https://myanimelist.net/anime/23273/Shigatsu_wa_Kimi_no_Uso',\n", "  'Ratings': '8.65'},\n", " '68': {'Rank': '68',\n", "  'Anime_name': 'Spy x Family',\n", "  'Anime_link': 'https://myanimelist.net/anime/50265/Spy_x_Family',\n", "  'Ratings': '8.65'},\n", " '69': {'Rank': '69',\n", "  'Anime_name': 'Haikyuu!! Second Season',\n", "  'Anime_link': 'https://myanimelist.net/anime/28891/Haikyuu_Second_Season',\n", "  'Ratings': '8.64'},\n", " '70': {'Rank': '70',\n", "  'Anime_name': 'Kaguya-sama wa Kokurasetai? Tensai-tachi no Renai Zunousen',\n", "  'Anime_link': 'https://myanimelist.net/anime/40591/Kaguya-sama_wa_Kokurasetai_Tensai-tachi_no_Renai_Zunousen',\n", "  'Ratings': '8.64'},\n", " '71': {'Rank': '71',\n", "  'Anime_name': 'Bungou Stray Dogs 4th Season',\n", "  'Anime_link': 'https://myanimelist.net/anime/50330/Bungou_Stray_Dogs_4th_Season',\n", "  'Ratings': '8.63'},\n", " '72': {'Rank': '72',\n", "  'Anime_name': 'Chainsaw Man',\n", "  'Anime_link': 'https://myanimelist.net/anime/44511/Chainsaw_Man',\n", "  'Ratings': '8.63'},\n", " '73': {'Rank': '73',\n", "  'Anime_name': 'Kimetsu no Yaiba Movie: Mugen Ressha-hen',\n", "  'Anime_link': 'https://myanimelist.net/anime/40456/Kimetsu_no_Yaiba_Movie__Mugen_Ressha-hen',\n", "  'Ratings': '8.63'},\n", " '74': {'Rank': '74',\n", "  'Anime_name': 'Made in Abyss Movie 3: Fukaki Tamashii no Reimei',\n", "  'Anime_link': 'https://myanimelist.net/anime/36862/Made_in_Abyss_Movie_3__Fukaki_Tamashii_no_Reimei',\n", "  'Ratings': '8.63'},\n", " '75': {'Rank': '75',\n", "  'Anime_name': 'Tengen Toppa Gurren Lagann',\n", "  'Anime_link': 'https://myanimelist.net/anime/2001/Tengen_Toppa_Gurren_Lagann',\n", "  'Ratings': '8.63'},\n", " '76': {'Rank': '76',\n", "  'Anime_name': 'Natsume Yuujinchou Roku',\n", "  'Anime_link': 'https://myanimelist.net/anime/34591/Natsume_Yuujinchou_Roku',\n", "  'Ratings': '8.62'},\n", " '77': {'Rank': '77',\n", "  'Anime_name': 'Ping Pong the Animation',\n", "  'Anime_link': 'https://myanimelist.net/anime/22135/Ping_Pong_the_Animation',\n", "  'Ratings': '8.62'},\n", " '78': {'Rank': '78',\n", "  'Anime_name': 'Shingeki no Kyojin Season 3',\n", "  'Anime_link': 'https://myanimelist.net/anime/35760/Shingeki_no_Kyojin_Season_3',\n", "  'Ratings': '8.62'},\n", " '79': {'Rank': '79',\n", "  'Anime_name': 'Death Note',\n", "  'Anime_link': 'https://myanimelist.net/anime/1535/Death_Note',\n", "  'Ratings': '8.62'},\n", " '80': {'Rank': '80',\n", "  'Anime_name': 'Cyberpunk: Edgerunners',\n", "  'Anime_link': 'https://myanimelist.net/anime/42310/Cyberpunk__Edgerunners',\n", "  'Ratings': '8.61'},\n", " '81': {'Rank': '81',\n", "  'Anime_name': 'Evangelion: 3.0+1.0 Thrice Upon a Time',\n", "  'Anime_link': 'https://myanimelist.net/anime/3786/Evangelion__30_10_Thrice_Upon_a_Time',\n", "  'Ratings': '8.61'},\n", " '82': {'Rank': '82',\n", "  'Anime_name': 'Mo Dao Zu Shi: Wanjie Pian',\n", "  'Anime_link': 'https://myanimelist.net/anime/40434/Mo_Dao_Zu_Shi__Wanjie_Pian',\n", "  'Ratings': '8.61'},\n", " '83': {'Rank': '83',\n", "  'Anime_name': 'Seishun Buta Yarou wa Yumemiru Shoujo no Yume wo Minai',\n", "  'Anime_link': 'https://myanimelist.net/anime/38329/Seishun_Buta_Yarou_wa_Yumemiru_Shoujo_no_Yume_wo_Minai',\n", "  'Ratings': '8.61'},\n", " '84': {'Rank': '84',\n", "  'Anime_name': 'Suzume no Tojimari',\n", "  'Anime_link': 'https://myanimelist.net/anime/50594/Suzume_no_Tojimari',\n", "  'Ratings': '8.61'},\n", " '85': {'Rank': '85',\n", "  'Anime_name': 'Suzumiya Haruhi no Shoushitsu',\n", "  'Anime_link': 'https://myanimelist.net/anime/7311/Suzumiya_Haruhi_no_Shoushitsu',\n", "  'Ratings': '8.61'},\n", " '86': {'Rank': '86',\n", "  'Anime_name': 'Mushishi Zoku Shou: Suzu no Shizuku',\n", "  'Anime_link': 'https://myanimelist.net/anime/28957/Mushishi_Zoku_Shou__Suzu_no_Shizuku',\n", "  'Ratings': '8.60'},\n", " '87': {'Rank': '87',\n", "  'Anime_name': 'Hajime no Ippo: Rising',\n", "  'Anime_link': 'https://myanimelist.net/anime/19647/Hajime_no_Ippo__Rising',\n", "  'Ratings': '8.59'},\n", " '88': {'Rank': '88',\n", "  'Anime_name': 'JoJo no Kimyou na Bouken Part 5: Ougon no Kaze',\n", "  'Anime_link': 'https://myanimelist.net/anime/37991/JoJo_no_Kimyou_na_Bouken_Part_5__Ougon_no_Kaze',\n", "  'Ratings': '8.58'},\n", " '89': {'Rank': '89',\n", "  'Anime_name': 'Kizumonogatari II: Nekketsu-hen',\n", "  'Anime_link': 'https://myanimelist.net/anime/31757/Kizumonogatari_II__Nekketsu-hen',\n", "  'Ratings': '8.58'},\n", " '90': {'Rank': '90',\n", "  'Anime_name': 'Natsume Yuujinchou San',\n", "  'Anime_link': 'https://myanimelist.net/anime/10379/Natsume_Yuujinchou_San',\n", "  'Ratings': '8.58'},\n", " '91': {'Rank': '91',\n", "  'Anime_name': 'Ookami Kodomo no Ame to Yuki',\n", "  'Anime_link': 'https://myanimelist.net/anime/12355/Ookami_Kodomo_no_Ame_to_Yuki',\n", "  'Ratings': '8.58'},\n", " '92': {'Rank': '92',\n", "  'Anime_name': 'Natsume Yuujinchou Go',\n", "  'Anime_link': 'https://myanimelist.net/anime/32983/Natsume_Yuujinchou_Go',\n", "  'Ratings': '8.57'},\n", " '93': {'Rank': '93',\n", "  'Anime_name': 'Shouwa Genroku Rakugo Shinjuu',\n", "  'Anime_link': 'https://myanimelist.net/anime/28735/Shouwa_Genroku_Rakugo_Shinjuu',\n", "  'Ratings': '8.57'},\n", " '94': {'Rank': '94',\n", "  'Anime_name': 'Tengen Toppa Gurren Lagann Movie 2: Lagann-hen',\n", "  'Anime_link': 'https://myanimelist.net/anime/4565/Tengen_Toppa_Gurren_Lagann_Movie_2__Lagann-hen',\n", "  'Ratings': '8.57'},\n", " '95': {'Rank': '95',\n", "  'Anime_name': 'Yojouhan Shinwa Taikei',\n", "  'Anime_link': 'https://myanimelist.net/anime/7785/Yojouhan_Shinwa_Taikei',\n", "  'Ratings': '8.57'},\n", " '96': {'Rank': '96',\n", "  'Anime_name': 'Ousama Ranking',\n", "  'Anime_link': 'https://myanimelist.net/anime/40834/Ousama_Ranking',\n", "  'Ratings': '8.56'},\n", " '97': {'Rank': '97',\n", "  'Anime_name': 'Fruits Basket 2nd Season',\n", "  'Anime_link': 'https://myanimelist.net/anime/40417/Fruits_Basket_2nd_Season',\n", "  'Ratings': '8.56'},\n", " '98': {'Rank': '98',\n", "  'Anime_name': 'Karakai Jouzu no Takagi-san Movie',\n", "  'Anime_link': 'https://myanimelist.net/anime/49722/Karakai_Jouzu_no_Takagi-san_Movie',\n", "  'Ratings': '8.56'},\n", " '99': {'Rank': '99',\n", "  'Anime_name': 'Kenpuu Denki Berserk',\n", "  'Anime_link': 'https://myanimelist.net/anime/33/Kenpuu_Denki_Berserk',\n", "  'Ratings': '8.56'},\n", " '100': {'Rank': '100',\n", "  'Anime_name': 'Kimi no Suizou wo Tabetai',\n", "  'Anime_link': 'https://myanimelist.net/anime/36098/Kimi_no_Suizou_wo_Tabetai',\n", "  'Ratings': '8.56'}}"]}, "execution_count": 29, "metadata": {}, "output_type": "execute_result"}], "source": ["get_top_anime(2)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We get dictionary containing the information parsed from the page_number given by the user using `get_top_anime` function.We merge the values in multiple dictionary using a for loop to get a dictionary `top_animes_dict` containing 200 rows and 4 columns.Click on [dict](https://datagy.io/python-merge-dictionaries/) to see 7 different ways in 2 dictionaries can be merged."]}, {"cell_type": "code", "execution_count": 30, "metadata": {}, "outputs": [], "source": ["top_animes_dict={}\n", "for i in range (1,5):\n", "    anime=get_top_anime(i)\n", "    top_animes_dict= top_animes_dict|anime"]}, {"cell_type": "code", "execution_count": 31, "metadata": {}, "outputs": [{"data": {"text/plain": ["200"]}, "execution_count": 31, "metadata": {}, "output_type": "execute_result"}], "source": ["len (top_animes_dict)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["##  _Creating a dataframe_\n", "\n", "\n", "Putting list of  the values extracted above to a dictionary and coverting it into a dataframe using [Pandas](https://pandas.pydata.org/docs/) dataframe.A dictionary containing information about the top animes can be obtained."]}, {"cell_type": "code", "execution_count": 32, "metadata": {}, "outputs": [], "source": ["!pip install pandas --upgrade --quiet"]}, {"cell_type": "code", "execution_count": 33, "metadata": {}, "outputs": [], "source": ["# importing pandas library\n", "import pandas as pd"]}, {"cell_type": "code", "execution_count": 34, "metadata": {}, "outputs": [], "source": ["top_animes_df=pd.DataFrame(top_animes_dict.values())"]}, {"cell_type": "code", "execution_count": 35, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>Rank</th>\n", "      <th>Anime_name</th>\n", "      <th>Anime_link</th>\n", "      <th>Ratings</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>1</td>\n", "      <td>Shingeki no Kyojin: The Final Season - Kankets...</td>\n", "      <td>https://myanimelist.net/anime/51535/Shingeki_n...</td>\n", "      <td>9.15</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>2</td>\n", "      <td>Fullmetal Alchemist: Brotherhood</td>\n", "      <td>https://myanimelist.net/anime/5114/Fullmetal_A...</td>\n", "      <td>9.11</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>3</td>\n", "      <td>Bleach: Sennen Kessen-hen</td>\n", "      <td>https://myanimelist.net/anime/41467/Bleach__Se...</td>\n", "      <td>9.09</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>4</td>\n", "      <td>Steins;Gate</td>\n", "      <td>https://myanimelist.net/anime/9253/Steins_Gate</td>\n", "      <td>9.08</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>5</td>\n", "      <td>Gintama\u00b0</td>\n", "      <td>https://myanimelist.net/anime/28977/Gintama\u00b0</td>\n", "      <td>9.07</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["  Rank                                         Anime_name  \\\n", "0    1  Shingeki no Kyojin: The Final Season - Kankets...   \n", "1    2                   Fullmetal Alchemist: Brotherhood   \n", "2    3                          Bleach: Sennen Kessen-hen   \n", "3    4                                        Steins;Gate   \n", "4    5                                           Gintama\u00b0   \n", "\n", "                                          Anime_link Ratings  \n", "0  https://myanimelist.net/anime/51535/Shingeki_n...    9.15  \n", "1  https://myanimelist.net/anime/5114/Fullmetal_A...    9.11  \n", "2  https://myanimelist.net/anime/41467/Bleach__Se...    9.09  \n", "3     https://myanimelist.net/anime/9253/Steins_Gate    9.08  \n", "4       https://myanimelist.net/anime/28977/Gintama\u00b0    9.07  "]}, "execution_count": 35, "metadata": {}, "output_type": "execute_result"}], "source": ["top_animes_df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Displaying the first 5 rows of the dataframe using the head function."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## _Converting into a CSV file_\n", "\n", "Lets write the top_animes_df dataframe  into a csv file."]}, {"cell_type": "code", "execution_count": 36, "metadata": {}, "outputs": [], "source": ["top_animes_df.to_csv(\"top_animes_list.csv\",index=None)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["`top_animes_list.csv`  contains the information about the top_animes upto rank 200. First 10 values within the CSV files  is printed for reference using the head function to understand the structure of the information within the CSV file."]}, {"cell_type": "code", "execution_count": 37, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Rank,Anime_name,Anime_link,Ratings\r\n", "1,Shingeki no Kyojin: The Final Season - Kanketsu-hen,https://myanimelist.net/anime/51535/Shingeki_no_Kyojin__The_Final_Season_-_Kanketsu-hen,9.15\r\n", "2,Fullmetal Alchemist: Brotherhood,https://myanimelist.net/anime/5114/Fullmetal_Alchemist__Brotherhood,9.11\r\n", "3,Bleach: Sennen Kessen-hen,https://myanimelist.net/anime/41467/Bleach__Sennen_Kessen-hen,9.09\r\n", "4,Steins;Gate,https://myanimelist.net/anime/9253/Steins_Gate,9.08\r\n", "5,Gintama\u00b0,https://myanimelist.net/anime/28977/Gintama\u00b0,9.07\r\n", "6,Kaguya-sama wa Kokurasetai: Ultra Romantic,https://myanimelist.net/anime/43608/Kaguya-sama_wa_Kokurasetai__Ultra_Romantic,9.06\r\n", "7,Shingeki no Kyojin Season 3 Part 2,https://myanimelist.net/anime/38524/Shingeki_no_Kyojin_Season_3_Part_2,9.06\r\n", "8,Gintama: The Final,https://myanimelist.net/anime/39486/Gintama__The_Final,9.05\r\n", "9,Gintama',https://myanimelist.net/anime/9969/Gintama,9.04\r\n"]}], "source": ["!head top_animes_list.csv"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## _Summary_\n", "\n", "\n", "In this project we have done the following tasks:                          \n", "1)Downloading the webpage using Requests.                                                       \n", "2)Extracting information from the HTML source code of a webpage programmatically, using the BeautifulSoup library.                                                                                          \n", "3)Creating a BeautifulSoup object to parse the content within the Source code.                    \n", "4)Compiling the extracted information into python lists and dictionaries.                        \n", "5)Creating a dataframe of the  webpage using pandas .                                      \n", "6)Converting the pandas dataframe to a csv file.                                               \n", "\n", "\n", "The CSV file contains data in the following format:                                                 \n", "`Rank,Anime_Name,Anime_Link,Ratings\n", "1,Shingeki no Kyojin: The Final Season - Kanketsu-hen,https://myanimelist.net/anime/51535/Shingeki_no_Kyojin__The_Final_Season_-_Kanketsu-hen,9.17\n", "2,Fullmetal Alchemist: Brotherhood,https://myanimelist.net/anime/5114/Fullmetal_Alchemist__Brotherhood,9.11`"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## _Future Works_\n", "\n", "\n", "\n", "We can scrape web page to obtain information on the different types of categories such as  Top Airing ,Top Upcoming ,Top TV Series, Top Movies, Top OVAs('Original Video Animation) ,Top ONAs (Original Net Animation),Top Specials ,Most Popular, Most Favourited animes .The project can be carried out further to analyze the web page to obtain information on the individual animes .The information that can be collected can be Details ,Characters & Staff ,Episodes, Videos, Stats, Reviews ,Recommendations ,Interest, Stacks ,News, Forum ,Clubs, Pictures on each animes.\n", "\n", "The data collected can be used to analyse the genre of the anime that  most people are attracted to,the trend in the number of viewers in relation to the  number of episodes .The age group or gender along which a particular anime is popular based on the review by viewers and  the number of likes provided by the user.Also the kind of way in an Anime is preferred by the user as in the form of movies or Series."]}], "metadata": {"language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.7"}}, "nbformat": 4, "nbformat_minor": 2}